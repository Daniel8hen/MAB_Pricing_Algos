{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from contextualbandits import online as cb\n",
    "from copy import deepcopy as clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# The only classifiers that have partial_fit\n",
    "# See: https://scikit-learn.org/0.15/modules/scaling_strategies.html\n",
    "from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "%matplotlib inline\n",
    "from wrappers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_win_rate=0.33\n",
    "\n",
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "\n",
    "df = df.query(\"placementType=='banner' and bidPrice<2 and bidPrice>0.1\").sample(frac=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_values_by_min_freq(df, col, freq=0.9,other=\"OTHER\"):\n",
    "    ds = df[col].value_counts(normalize=True).cumsum()\n",
    "    mapped2other = []\n",
    "    marked_as_other = False\n",
    "    for val, prop in ds.iteritems():\n",
    "        if marked_as_other:\n",
    "            mapped2other.append(val)\n",
    "        if prop>freq:\n",
    "            marked_as_other=True\n",
    "    df.loc[df[col].isin(mapped2other), col]=other\n",
    "    df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.drop(\"sessionId\", axis=1)\n",
    "    df[\"eventTimestamp\"] = pd.to_datetime(df[\"eventTimestamp\"]*1_000_000)\n",
    "#     df[\"day_of_week\"]=df[\"eventTimestamp\"].dt.weekday.astype(\"category\")\n",
    "#     df[\"time_of_day\"]=df[\"eventTimestamp\"].dt.hour.astype(\"category\")\n",
    "    df.sort_values(by='eventTimestamp', inplace=True)    \n",
    "    df = df.drop(\"eventTimestamp\", axis=1)\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if str(dtype) == 'object':\n",
    "            df = keep_values_by_min_freq(df, col)\n",
    "    \n",
    "#     df = keep_values_by_min_freq(df, 'adNetworkId')\n",
    "    df = keep_values_by_min_freq(df, 'userTrackingAuth')\n",
    "    # a, r, X for models\n",
    "    df[\"arms\"] = df[\"bidPrice\"].round(2)\n",
    "    arms = sorted(list(df[\"arms\"].unique()))\n",
    "    # Add the logic of: \"If $5 won, then $6 would have won as well\" (also for loss)\n",
    "    df[\"arms\"] = df.apply(lambda row: [a for a in arms if a>=row[\"arms\"]] if row[\"hasWon\"] else\n",
    "                          [a for a in arms if a<=row[\"arms\"]],axis=1)\n",
    "    df = df.explode(\"arms\")\n",
    "    arm_dict = {a:i for i, a in enumerate(arms)}\n",
    "    a = df[\"arms\"].map(arm_dict)\n",
    "    r = df[\"hasWon\"]\n",
    "    df = df.drop([\"bidPrice\", \"hasWon\", \"arms\", \"advertisedBundle\"] ,axis=1)\n",
    "    X = pd.get_dummies(df)\n",
    "    return arm_dict, X, a, r\n",
    "\n",
    "def preprocess_only_one_feature(df, feature='deviceOs'):\n",
    "    # preprocess\n",
    "    df = df[['bidPrice', 'hasWon', feature]]\n",
    "    df[\"arms\"] = df[\"bidPrice\"].round(1)\n",
    "    arms = sorted(list(df[\"arms\"].unique()))\n",
    "    # Add the logic of: \"If $5 won, then $6 would have won as well\" (also for loss)\n",
    "    df[\"arms\"] = df.apply(lambda row: [a for a in arms if a>=row[\"arms\"]] if row[\"hasWon\"] else\n",
    "                          [a for a in arms if a<=row[\"arms\"]],axis=1)\n",
    "    df = df.explode(\"arms\")\n",
    "    \n",
    "    arm_dict = {a:i for i, a in enumerate(arms)}\n",
    "    a = df[\"arms\"].map(arm_dict)\n",
    "    r = df[\"hasWon\"]\n",
    "    df = df.drop([\"bidPrice\", \"hasWon\", \"arms\"] ,axis=1)\n",
    "    X = pd.get_dummies(df)\n",
    "    \n",
    "    return arm_dict, X, a, r\n",
    "\n",
    "\n",
    "# sample\n",
    "### Note for arms - we should know in advance, per each context, what is the maximum bid\n",
    "# e.g. for iOS, size=320x50, plc=Banner, we should know that 10 is the maximum and not create an arm for X>10...\n",
    "# Maybe - it should be calculated every X days (1 day...)\n",
    "\n",
    "# df = df.query(\"placementType=='banner' and bidPrice<1.01\").drop(\"placementType\",axis=1)\n",
    "df.drop(\"placementType\", axis=1)\n",
    "\n",
    "arm_dict, X, a, r = preprocess(df)\n",
    "# df[\"deviceOs_size\"] = df[\"deviceOs\"] + '_' + df[\"size\"]\n",
    "# arm_dict, X, a, r = preprocess_only_one_feature(df, 'deviceOs_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithDesiredWinRate(BernoulliNB):\n",
    "    def predict_proba(self, X):\n",
    "        probs = super().predict_proba(X)[:, 1] # predict proba as of any predict_proba model classifier\n",
    "        y = 1 / np.abs(probs - desired_win_rate + 0.0001) # Numerical stability\n",
    "        c = 1e-3\n",
    "        y = 1 - np.exp(-y*c) # Normalize\n",
    "        ret = np.vstack((1-y, y)).T\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDClassifierWithNormalization(SGDClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        probs = super().predict_proba(X)[:, 1] # predict proba as of any predict_proba model classifier\n",
    "        y = 1 / np.abs(probs - desired_win_rate + 0.0001) # Numerical stability\n",
    "        c = 1e-3\n",
    "        y = 1 - np.exp(-y*c) # Normalize\n",
    "        ret = np.vstack((1-y, y)).T\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_arms = len(arm_dict)\n",
    "bids = {v:k for k,v in arm_dict.items()}\n",
    "base_model = SGDClassifierWithNormalization(loss='log')\n",
    "# base_model = ModelWithDesiredWinRate()\n",
    "# base_model = BernoulliNB()\n",
    "logreg_sg = cb.SeparateClassifiers(clone(base_model), n_arms, batch_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_sg.partial_fit(X,a,r)\n",
    "print(type(logreg_sg._oracles.algos[0]))\n",
    "assert type(base_model) == type(logreg_sg._oracles.algos[0])\n",
    "\n",
    "# model.partial_fit(XX, aa, rr)\n",
    "# [m.coef_ for m in model._oracles.algos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_sg.fit(X,a,r)\n",
    "# [m.coef_ for m in logreg_sg._oracles.algos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(model, X, a , r, chunk = 100, limit=500):\n",
    "    X,a,r=map(clone,[X,a,r]) # copy the existing data so we won't change it\n",
    "    \n",
    "    ### TODO: Update reward with neighbor arms\n",
    "    \n",
    "    train_X, train_a, train_r = X.iloc[:chunk,:], a[:chunk], r[:chunk] \n",
    "    # split the data into train\n",
    "    # Get chunk data points for first input\n",
    "    X, a, r = X.iloc[chunk:,:], a[chunk:], r[chunk:]\n",
    "    test_X, test_a, test_r = X.iloc[:chunk,:], a[:chunk], r[:chunk]\n",
    "    n_iterations = 1\n",
    "    regrets = []\n",
    "    \n",
    "    while len(X)>chunk:\n",
    "        model.partial_fit(train_X,train_a,train_r)\n",
    "        pred_bids = model.predict(test_X)\n",
    "        regrets.append(np.sum([np.abs(bids[i]-y) for i,y in zip(pred_bids,test_r.values)])/chunk)\n",
    "        train_X, train_a, train_r    = X.iloc[:chunk,:], a[:chunk], r[:chunk]\n",
    "        X, a, r = X.iloc[chunk:,:], a[chunk:], r[chunk:]\n",
    "        test_X, test_a, test_r = X.iloc[:chunk,:], a[:chunk], r[:chunk]\n",
    "        n_iterations+=1\n",
    "        if limit>0 and limit<n_iterations:\n",
    "            break\n",
    "            \n",
    "    return regrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret = simulate(logreg_sg, X, a, r)\n",
    "plt.plot(np.arange(len(regret)), regret)\n",
    "plt.ylabel(\"regret\")\n",
    "plt.xlabel(\"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "pred = logreg_sg.predict(np.eye(len(X.columns)), output_score=True)\n",
    "pred[\"bid\"] = [bids[y] for y in pred['choice']]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"deviceOs\").agg({\"bidPrice\": np.mean, \"sessionId\": 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values=\"bidPrice\", index=\"deviceOs\", columns=\"hasWon\", aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(values=\"bidPrice\", index=\"size\", columns=\"hasWon\", aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('hasWon==1').pivot_table(values=\"bidPrice\", index=\"deviceOs\", columns=\"size\", aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deviceOs_size'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
